# ============================================================
# preLLM .env — LiteLLM-compatible configuration
# ============================================================
# Copy this file: cp .env.example .env
# Fill in ONLY the keys you need. Everything else has sensible defaults.
#
# 100% compatible with existing LiteLLM .env files.
# Your LiteLLM .env works immediately — just add PRELLM_SMALL_DEFAULT.

# ========== PRELLM PROXY AUTH ==========
# Master key for API authentication (like LiteLLM proxy)
# Leave empty to disable auth (dev mode)
LITELLM_MASTER_KEY=

# ========== SMALL LLM (local preprocessing) ==========
# Ollama runs locally — no API key needed
OLLAMA_API_BASE=http://localhost:11434

# ========== LARGE LLM PROVIDERS (remote execution) ==========
# Fill in ONLY the providers you use. LiteLLM routes automatically.

# Anthropic Claude
ANTHROPIC_API_KEY=
# ANTHROPIC_BASE_URL=https://api.anthropic.com/v1

# OpenAI / GPT
OPENAI_API_KEY=
# OPENAI_BASE_URL=https://api.openai.com/v1

# Groq (fast + cheap)
GROQ_API_KEY=
# GROQ_BASE_URL=https://api.groq.com/openai/v1

# Mistral
MISTRAL_API_KEY=
# MISTRAL_BASE_URL=https://api.mistral.ai/v1

# Azure OpenAI
# AZURE_API_KEY=
# AZURE_API_BASE=
# AZURE_API_VERSION=2024-02-01

# Google Vertex / Gemini
# GOOGLE_APPLICATION_CREDENTIALS=
# VERTEX_PROJECT=
# VERTEX_LOCATION=

# AWS Bedrock
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=
# AWS_REGION_NAME=

# ========== PRELLM DEFAULTS ==========
# Default model pair (LiteLLM model naming)
PRELLM_SMALL_DEFAULT=ollama/qwen2.5:3b
PRELLM_LARGE_DEFAULT=gpt-4o-mini

# Default decomposition strategy: classify|structure|split|enrich|passthrough
PRELLM_STRATEGY=classify

# Fallback chain (comma-separated, tried in order if primary fails)
# PRELLM_FALLBACKS=gpt-4o-mini,anthropic/claude-sonnet-4-20250514,groq/llama-3.3-70b-versatile

# ========== PRELLM SERVER ==========
PRELLM_HOST=0.0.0.0
PRELLM_PORT=8080

# YAML config file (optional, overrides env defaults)
# PRELLM_CONFIG=configs/prellm_config.yaml

# ========== BUDGET & LIMITS (optional) ==========
# PRELLM_MONTHLY_BUDGET=50.0
# PRELLM_MAX_TOKENS=4096
# PRELLM_TIMEOUT=30

# ========== LOGGING ==========
# PRELLM_LOG_LEVEL=info
