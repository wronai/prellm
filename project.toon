# prellm | 30f 7543L | python:29/javascript:1
# Keys: M=modules, D=details, i=imports, c=classes, f=functions, m=methods
M[30]:
  examples/python_sdk.py,163
  prellm/env_config.py,145
  prellm/cli.py,357
  prellm/server.py,330
  prellm/__init__.py,48
  prellm/query_decomposer.py,231
  prellm/prompt_registry.py,136
  prellm/models.py,198
  prellm/core.py,389
  prellm/llm_provider.py,110
  prellm/pipeline.py,290
  tests/test_one_function.py,307
  tests/test_edge_cases.py,78
  tests/test_promptguard.py,159
  tests/test_server.py,246
  tests/test_decomposer.py,187
  tests/test_env_config.py,244
  tests/__init__.py,0
  tests/test_context.py,44
  tests/test_v2_architecture.py,519
  tests/test_models.py,172
  tests/test_integration.py,194
  tests/test_prompt_registry.py,119
  tests/test_pipeline.py,293
  htmlcov/coverage_html_cb_dd2e7eb5.js,555
  prellm/chains/__init__.py,0
  prellm/chains/process_chain.py,194
  prellm/analyzers/bias_detector.py,76
  prellm/analyzers/__init__.py,0
  prellm/analyzers/context_engine.py,75
D:
  examples/python_sdk.py:
    i: asyncio
    e: example_one_function,example_domain_rules,example_sync,example_class_based,example_openai_sdk,example_batch,example_strategies,main
    example_one_function()
    example_domain_rules()
    example_sync()
    example_class_based()
    example_openai_sdk()
    example_batch()
    example_strategies()
    main()
  prellm/env_config.py:
    i: logging,os,dataclasses.{dataclass,field},pathlib.Path,typing.Any
    e: PROVIDER_KEY_MAP,EnvConfig,load_dotenv_if_available,get_env_config,check_providers,check_providers_live
    EnvConfig:   # Resolved environment configuration.
    load_dotenv_if_available(path:Any=None)->None
    get_env_config(dotenv_path:Any=None)->EnvConfig
    check_providers(env:Any=None)->dict[str, dict[str, Any]]
    check_providers_live(env:Any=None)->dict[str, dict[str, Any]]
  prellm/cli.py:
    i: asyncio,json,sys,typer,pathlib.Path,typing.Optional
    e: query,run,process,analyze,decompose,init,serve,doctor
    query(prompt:str=typer.Argument(...; help='The prompt/query to preprocess and execute');small:str=typer.Option('ollama/qwen2.5:3b'; '--small'; '-s'; help='Small LLM for preprocessing');large:str=typer.Option('gpt-4o-mini'; '--large'; '-l'; help='Large LLM for execution');strategy:str=typer.Option('classify'; '--strategy'; '-S'; help='Strategy: classify|structure|split|enrich|passthrough');context:Optional[str]=typer.Option(None; '--context'; '-C'; help="User context tag (e.g. 'gdansk_embedded_python')");config:Optional[Path]=typer.Option(None; '--config'; '-c'; help='Optional YAML config file');...+1)
    run(query:str=typer.Argument(...; help='The prompt/query to process');config:Path=typer.Option('rules.yaml'; '--config'; '-c'; help='Path to YAML config');model:str=typer.Option('gpt-4o-mini'; '--model'; '-m'; help='LLM model to use');dry_run:bool=typer.Option(False; '--dry-run'; '-d'; help="Analyze only; don't call LLM");json_output:bool=typer.Option(False; '--json'; '-j'; help='Output as JSON'))
    process(config:Path=typer.Argument(...; help='Path to process chain YAML');guard_config:Path=typer.Option('rules.yaml'; '--guard-config'; '-g'; help='Path to guard YAML config');dry_run:bool=typer.Option(False; '--dry-run'; '-d'; help='Analyze steps without calling LLM');json_output:bool=typer.Option(False; '--json'; '-j'; help='Output as JSON');env:Optional[str]=typer.Option(None; '--env'; '-e'; help='Environment override (e.g.; production)'))
    analyze(query:str=typer.Argument(...; help='Query to analyze for bias/ambiguity');config:Path=typer.Option('rules.yaml'; '--config'; '-c'; help='Path to YAML config'))
    decompose(query:str=typer.Argument(...; help='The prompt/query to decompose');config:Path=typer.Option('configs/prellm_config.yaml'; '--config'; '-c'; help='Path to preLLM v0.2 YAML config');strategy:str=typer.Option('classify'; '--strategy'; '-s'; help='Decomposition strategy: classify|structure|split|enrich|passthrough');json_output:bool=typer.Option(False; '--json'; '-j'; help='Output as JSON'))
    init(output:Path=typer.Option('rules.yaml'; '--output'; '-o'; help='Output path for config');devops:bool=typer.Option(False; '--devops'; help='Include DevOps-specific patterns');v2:bool=typer.Option(False; '--v2'; help='Generate preLLM v0.2 config instead of v0.1'))
    serve(host:str=typer.Option('0.0.0.0'; '--host'; '-H'; help='Bind host');port:int=typer.Option(8080; '--port'; '-p'; help='Bind port');small:Optional[str]=typer.Option(None; '--small'; '-s'; help='Override small LLM (default: from .env)');large:Optional[str]=typer.Option(None; '--large'; '-l'; help='Override large LLM (default: from .env)');strategy:Optional[str]=typer.Option(None; '--strategy'; '-S'; help='Override strategy (default: from .env)');config:Optional[Path]=typer.Option(None; '--config'; '-c'; help='YAML config file');...+1)
    doctor(env_file:Optional[Path]=typer.Option(None; '--env-file'; help='Path to .env file');live:bool=typer.Option(False; '--live'; help='Test live connectivity to providers'))
  prellm/server.py:
    i: asyncio,json,logging,os,time,uuid,fastapi.{FastAPI,HTTPException},typing.{Any,AsyncGenerator}
    e: SMALL_MODEL,LARGE_MODEL,DEFAULT_STRATEGY,CONFIG_PATH,MASTER_KEY,ChatMessage,PreLLMExtras,ChatCompletionRequest
    ChatMessage: 
    PreLLMExtras:   # preLLM-specific extensions in the req...
    ChatCompletionRequest: 
    ChatCompletionChoice: 
    UsageInfo: 
    _parse_model_pair(model_str:str)->tuple[str, str]
    _build_prellm_meta(result:PreLLMResponse;strategy:str)->PreLLMMeta
    health()->HealthResponse
    list_models()
    chat_completions(req:ChatCompletionRequest)
    _stream_response(query:str;small:str;large:str;strategy:str;extras:PreLLMExtras)->AsyncGenerator[str, None]
    batch_process(items:list[BatchItem])
    create_app(small_model:Any=None;large_model:Any=None;strategy:Any=None;config_path:Any=None;master_key:Any=None;dotenv_path:Any=None)->FastAPI
  prellm/query_decomposer.py:
    i: logging,prellm.llm_provider.LLMProvider,prellm.models,typing.Any
    e: QueryDecomposer
    QueryDecomposer: __init__(3),decompose(3),_classify(1),_structure(1),_split(1)  # Decomposes user queries using a small...
  prellm/prompt_registry.py:
    i: logging,yaml,functools.lru_cache,jinja2.{BaseLoader,Environment,TemplateSyntaxError,UndefinedError,_StrictUndefined},pathlib.Path,typing.Any
    e: _DEFAULT_PROMPTS_PATH,PromptNotFoundError,PromptRenderError,PromptEntry,PromptRegistry
    PromptNotFoundError:   # Raised when a prompt name is not foun...
    PromptRenderError:   # Raised when a prompt template fails t...
    PromptEntry: __init__(4),__repr__(0)  # Single prompt entry with template, ma...
    PromptRegistry: __init__(1),_ensure_loaded(0),_load(0),get(1),get_entry(1)  # Loads prompts from YAML, caches, vali...
    _StrictUndefined:   # Custom undefined that allows `default...
  prellm/models.py:
    i: enum,datetime,pydantic.{BaseModel,Field},typing.Any
    e: Policy,ApprovalMode,StepStatus,DecompositionStrategy,BiasPattern,ModelConfig,GuardConfig,AnalysisResult
    Policy: 
    ApprovalMode: 
    StepStatus: 
    DecompositionStrategy:   # Strategy for how the small LLM prepro...
    BiasPattern: 
  prellm/core.py:
    i: logging,datetime,yaml,pathlib.Path,prellm.analyzers.bias_detector.BiasDetector,prellm.analyzers.context_engine.ContextEngine,prellm.llm_provider.LLMProvider,prellm.models.{AuditEntry,BiasPattern},typing.Any
    e: preprocess_and_execute,preprocess_and_execute_sync,PreLLM,prellm
    PreLLM: __init__(2),__call__(3),decompose_only(3),get_audit_log(0),_audit(3)  # preLLM v0.2 — small LLM decomposition...
    prellm: __init__(2),__call__(3),analyze_only(1),get_audit_log(0),_audit(4)  # v0.1 Prellm middleware — analyze, enr...
    preprocess_and_execute(query:str;small_llm:str='ollama/qwen2.5:3b';large_llm:str='anthropic/claude-sonnet-4-20250514';strategy:Any='classify';user_context:Any=None;config_path:Any=None;...+1)->PreLLMResponse
    preprocess_and_execute_sync(query:str;small_llm:str='ollama/qwen2.5:3b';large_llm:str='anthropic/claude-sonnet-4-20250514';strategy:Any='classify';user_context:Any=None;config_path:Any=None;...+1)->PreLLMResponse
  prellm/llm_provider.py:
    i: json,logging,prellm.models.LLMProviderConfig,typing.Any
    e: LLMProvider
    LLMProvider: __init__(1),complete(3),complete_json(2),_parse_json(1)  # Unified LLM caller with retry and fal...
  prellm/pipeline.py:
    i: logging,yaml,pathlib.Path,prellm.llm_provider.LLMProvider,prellm.prompt_registry.PromptRegistry,pydantic.{BaseModel,Field},typing.{Any,Callable}
    e: _DEFAULT_PIPELINES_PATH,PipelineStep,PipelineConfig,StepExecutionResult,PipelineResult,PromptPipeline
    PipelineStep:   # Configuration for a single pipeline s...
    PipelineConfig:   # Configuration for a complete pipeline.
    StepExecutionResult:   # Result of executing a single pipeline...
    PipelineResult:   # Result of executing a full pipeline.
    PromptPipeline: __init__(4),from_yaml(5),execute(2),_execute_llm_step(2),_execute_algo_step(2)  # Generic pipeline — executes a sequenc...
  tests/test_one_function.py:
    i: pytest,prellm.core.{preprocess_and_execute,preprocess_and_execute_sync},prellm.models.{DecompositionStrategy,DomainRule,PreLLMResponse},unittest.mock.{AsyncMock,MagicMock,patch}
    e: TestPreprocessAndExecute,TestPreprocessAndExecuteSync,TestImportFromPackage
    TestPreprocessAndExecute: test_zero_config(0),test_custom_models(0),test_passthrough_strategy(0),test_strategy_as_enum(0),test_user_context_string(0)  # Core tests for the 1-function API.
    TestPreprocessAndExecuteSync: test_sync_wrapper_works(0)  # Tests for the synchronous wrapper.
    TestImportFromPackage: test_import_async(0),test_import_sync(0),test_version(0),test_all_exports(0)  # Test that the 1-function API is impor...
    _mock_litellm_response(content:str)->MagicMock
  tests/test_edge_cases.py:
    i: pytest,prellm.analyzers.bias_detector.{BiasDetector,DEFAULT_PATTERNS},prellm.models.BiasPattern
    e: TestPolishPatterns,TestMixedLanguage,TestBoundaryConditions
    TestPolishPatterns: test_polish_deploy_production(0),test_polish_delete_database(0),test_polish_always_bias(0),test_polish_only_bias(0),test_polish_safe_long_query(0)
    TestMixedLanguage: test_polish_english_mix(0),test_english_with_polish_verbs(0),test_polish_verb_no_target(0)
    TestBoundaryConditions: test_empty_query(0),test_single_word(0),test_very_long_safe_query(0),test_case_insensitive_patterns(0),test_no_false_positive_on_partial_match(0)
  tests/test_promptguard.py:
    i: pytest,pathlib.Path,prellm.models.{AnalysisResult,BiasPattern,GuardConfig,GuardResponse,ModelConfig},unittest.mock.{AsyncMock,MagicMock,patch}
    e: TestBiasDetector,TestContextEngine,TestprellmCore,TestProcessChainConfig,TestModels
    TestBiasDetector: test_detects_absolute_quantifier_pl(0),test_detects_absolute_quantifier_en(0),test_detects_production_deploy(0),test_detects_destructive_db_operation(0),test_detects_short_query(0)
    TestContextEngine: test_env_context(1),test_enrich_prompt(1),test_extra_context_override(1),test_missing_env_graceful(0),test_system_context(0)
    TestprellmCore: test_load_inline_config(0),test_analyze_only(0),test_analyze_only_clean(0),test_call_with_mock_litellm(0),test_call_with_clarification(0)
    TestProcessChainConfig: test_process_config_model(0),test_step_dependencies(0)
    TestModels: test_guard_response_defaults(0),test_analysis_result(0),test_config_defaults(0)
  tests/test_server.py:
    i: json,pytest,fastapi.testclient.TestClient,prellm.server.{_parse_model_pair,app,create_app},unittest.mock.{AsyncMock,MagicMock,patch}
    e: TestParseModelPair,TestHealthEndpoint,TestChatCompletions,TestStreamingEndpoint,TestBatchEndpoint,TestCreateApp
    TestParseModelPair: test_default(0),test_arrow_unicode(0),test_arrow_ascii(0),test_single_model(0),test_no_prefix(0)
    TestHealthEndpoint: test_health(0),test_models(0)
    TestChatCompletions: test_basic_completion(0),test_with_prellm_extras(0),test_with_yaml_response_format(0),test_prellm_meta_in_response(0),test_passthrough_strategy(0)
    TestStreamingEndpoint: test_streaming_response(0),test_streaming_with_stages(0)
    TestBatchEndpoint: test_batch_processing(0),test_batch_empty_error(0)
    _mock_litellm_response(content:str)->MagicMock
    _mock_completion_side_effect()
  tests/test_decomposer.py:
    i: json,pytest,prellm.llm_provider.LLMProvider,prellm.models.{ClassificationResult,DecompositionPrompts,DecompositionStrategy},prellm.query_decomposer.QueryDecomposer,unittest.mock.{AsyncMock,MagicMock,patch}
    e: TestLLMProvider,TestQueryDecomposer
    TestLLMProvider: test_complete_returns_content(0),test_complete_with_system_prompt(0),test_complete_json_parses(0),test_complete_json_handles_markdown_fence(0),test_complete_json_returns_empty_on_bad_json(0)
    TestQueryDecomposer: _make_decomposer(1),test_passthrough_strategy(0),test_classify_strategy(0),test_structure_strategy(0),test_split_strategy(0)
  tests/test_env_config.py:
    i: os,tempfile,pytest,prellm.env_config.{EnvConfig,check_providers,get_env_config,load_dotenv_if_available},unittest.mock.{AsyncMock,MagicMock,patch}
    e: TestEnvConfigDefaults,TestLoadDotenv,TestGetEnvConfig,TestCheckProviders,TestAuthMiddleware
    TestEnvConfigDefaults: test_default_config(0),test_provider_key_map_has_all_providers(0)
    TestLoadDotenv: test_load_env_file(1),test_load_env_does_not_override_existing(1),test_load_env_strips_quotes(1),test_load_nonexistent_file(0)
    TestGetEnvConfig: test_reads_from_env(0),test_reads_from_dotenv_file(1),test_litellm_compat_env_vars(0),test_small_model_fallback_to_old_env(0),test_empty_master_key_is_none(0)
    TestCheckProviders: test_check_with_keys(0),test_check_without_keys(0)
    TestAuthMiddleware: test_no_auth_when_no_master_key(0),test_auth_required_when_master_key_set(0),test_auth_with_bearer_token(0),test_auth_with_x_api_key(0),test_wrong_key_rejected(0)  # Test Bearer token auth in the API ser...
    _mock_resp(content:str)->MagicMock
  tests/test_context.py:
    i: pytest,prellm.analyzers.context_engine.ContextEngine
    e: TestContextEngine
    TestContextEngine: test_env_context(1),test_enrich_prompt(1),test_extra_overrides_env(1),test_missing_env_graceful(0),test_system_context(0)
  tests/test_v2_architecture.py:
    i: json,pytest,prellm.models.{ClassificationResult,DecompositionPrompts,DecompositionResult,DecompositionStrategy,DomainRule},unittest.mock.{AsyncMock,MagicMock,patch}
    e: TestLLMProvider,TestQueryDecomposer,TestDomainRule,TestPreLLMConfig,TestPreLLMCore,TestPreLLMConfigLoading,TestProcessChainV2,TestDecompositionResult
    TestLLMProvider: test_init_with_config(0),test_complete_success(0),test_complete_with_system_prompt(0),test_complete_fallback(0),test_complete_all_fail(0)
    TestQueryDecomposer: _make_decomposer(1),test_passthrough_strategy(0),test_classify_strategy(0),test_structure_strategy(0),test_split_strategy(0)
    TestDomainRule: test_defaults(0),test_full_rule(0)
    TestPreLLMConfig: test_defaults(0),test_custom_config(0)
    TestPreLLMCore: test_init_default(0),test_init_with_config(0),test_full_pipeline(0),test_decompose_only(0),test_passthrough_strategy(0)
  tests/test_models.py:
    i: os,tempfile,pytest,yaml,prellm.models
    e: TestModelDefaults,TestDomainRules,TestDecompositionStrategy,TestConfigLoading,TestProcessModels
    TestModelDefaults: test_llm_provider_config_defaults(0),test_prellm_config_defaults(0),test_response_defaults(0),test_decomposition_result_defaults(0),test_classification_result(0)
    TestDomainRules: test_rule_with_all_fields(0),test_rule_keyword_matching(0),test_rule_no_match(0)
    TestDecompositionStrategy: test_all_strategies_exist(0),test_strategy_from_string(0)
    TestConfigLoading: _write_yaml(1),test_load_minimal_config(0),test_load_with_models(0),test_load_with_domain_rules(0),test_load_with_prompts(0)
    TestProcessModels: test_process_step_with_strategy(0),test_process_config(0)
  tests/test_integration.py:
    i: os,tempfile,pytest,yaml,pathlib.Path,prellm.chains.process_chain.ProcessChain,prellm.core.prellm,unittest.mock.{AsyncMock,MagicMock,patch}
    e: TestYAMLConfigLoading,TestAnalyzeOnly,TestProcessChainDryRun,TestDeployConfig
    TestYAMLConfigLoading: _write_yaml(1),test_load_minimal_config(0),test_load_full_config(0),test_load_empty_config(0),test_configs_rules_yaml(0)
    TestAnalyzeOnly: test_production_deploy_detected(0),test_db_delete_detected(0),test_safe_query_passes(0),test_short_devops_query_flagged(0),test_scale_operation_detected(0)
    TestProcessChainDryRun: _make_chain(1),test_simple_chain_dry_run(0),test_chain_with_manual_approval_pauses(0),test_chain_with_approval_callback(0),test_chain_dependency_failure(0)
    TestDeployConfig: test_deploy_yaml_loads(0)
  tests/test_prompt_registry.py:
    i: tempfile,pytest,yaml,pathlib.Path,prellm.prompt_registry.{PromptNotFoundError,PromptRegistry,PromptRenderError}
    e: sample_prompts_yaml,registry,test_prompt_registry_loads_yaml,test_prompt_registry_get_with_variables,test_prompt_registry_get_with_default,test_prompt_registry_get_conditional,test_prompt_registry_missing_prompt_raises,test_prompt_registry_validate_all_required
    sample_prompts_yaml(tmp_path:Path)->Path
    registry(sample_prompts_yaml:Path)->PromptRegistry
    test_prompt_registry_loads_yaml(registry:PromptRegistry)
    test_prompt_registry_get_with_variables(registry:PromptRegistry)
    test_prompt_registry_get_with_default(registry:PromptRegistry)
    test_prompt_registry_get_conditional(registry:PromptRegistry)
    test_prompt_registry_missing_prompt_raises(registry:PromptRegistry)
    test_prompt_registry_validate_all_required(registry:PromptRegistry)
  tests/test_pipeline.py:
    i: pytest,yaml,pathlib.Path,prellm.llm_provider.LLMProvider,prellm.models.LLMProviderConfig,prellm.pipeline.{PipelineConfig,PipelineResult,PipelineStep},unittest.mock.{AsyncMock,MagicMock}
    e: sample_prompts_yaml,sample_pipelines_yaml,registry,mock_llm,test_pipeline_sequential_execution,test_pipeline_conditional_step_skip,test_pipeline_conditional_step_executes,test_pipeline_algo_step_execution
    sample_prompts_yaml(tmp_path:Path)->Path
    sample_pipelines_yaml(tmp_path:Path)->Path
    registry(sample_prompts_yaml:Path)->PromptRegistry
    mock_llm()->LLMProvider
    _make_pipeline(registry:PromptRegistry;mock_llm:LLMProvider;steps:list[dict];name:str='test')->PromptPipeline
    test_pipeline_sequential_execution(registry:PromptRegistry;mock_llm:LLMProvider)
    test_pipeline_conditional_step_skip(registry:PromptRegistry;mock_llm:LLMProvider)
    test_pipeline_conditional_step_executes(registry:PromptRegistry;mock_llm:LLMProvider)
  htmlcov/coverage_html_cb_dd2e7eb5.js:
    e: debounce,on_click,checkVisible,sortColumn,rowComparator,getCellValue
    debounce(callback;wait)
    checkVisible(element)
    on_click(sel;fn)
    getCellValue(row)
    rowComparator(rowA;rowB)
    sortColumn(th)
  prellm/chains/process_chain.py:
    i: logging,time,datetime,yaml,pathlib.Path,prellm.analyzers.context_engine.ContextEngine,typing.{Any,Awaitable,Callable,Union}
    e: ProcessChain
    ProcessChain: __init__(5),execute(3),_execute_step(4),get_audit_log(0),_audit_step(3)  # Execute multi-step DevOps workflows w...
  prellm/analyzers/bias_detector.py:
    i: re,prellm.models.{AnalysisResult,BiasPattern},typing.Any
    e: DEFAULT_PATTERNS,BiasDetector
    BiasDetector: __init__(1),analyze(1)  # Detects bias, ambiguity, and dangerou...
  prellm/analyzers/context_engine.py:
    i: os,subprocess,typing.Any
    e: ContextEngine
    ContextEngine: __init__(1),gather(0),enrich_prompt(2),_gather_env(1),_gather_git(1)  # Collects context from environment, gi...